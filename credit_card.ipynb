{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcFQ-b_6_MlM"
      },
      "outputs": [],
      "source": [
        "# Loading the libraries\n",
        "import numpy as np\n",
        "# numpy stands for numerical python\n",
        "import pandas as pd\n",
        "# pandas stands for panel data\n",
        "import matplotlib.pyplot as plt\n",
        "# Matlab plot library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SQR0eCy_RNg"
      },
      "outputs": [],
      "source": [
        "# read the data file\n",
        "dataset = pd.read_csv(\"Churn_Modelling.csv\")\n",
        "# Check is the data is properly loaded\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw7joE06_R4Z"
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:,3:13].values\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIOz4RcX_WpQ"
      },
      "outputs": [],
      "source": [
        "# To make things work on python we have to convert the panel data into numpy array\n",
        "y = dataset.iloc[:,13].values\n",
        "type(y)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy07PQ9C_ZHz"
      },
      "outputs": [],
      "source": [
        "# Importing the relevant libraries from sklearn preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "# Pass on the functionality of the library LabelEncoder to another variable\n",
        "labelencoder = LabelEncoder()\n",
        "X[:,2] = labelencoder.fit_transform(X[:,2])\n",
        "X\n",
        "# The next step is to label encode the geography\n",
        "X[:,1] = labelencoder.fit_transform(X[:,1])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL9NNfcn_crQ"
      },
      "outputs": [],
      "source": [
        "# Get the library from sklearn.compose\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# OneHot Encoder has been applied to column 1\n",
        "# I have given the ColumnTransformer function a name of my choice which is country\n",
        "# The functionality has been passed onto the variable ct but still not applied on the data\n",
        "ct = ColumnTransformer([(\"Country\", OneHotEncoder(), [1])], remainder = 'passthrough')\n",
        "# We shall now apply it on the data\n",
        "X = ct.fit_transform(X)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQqjcp3__hEN"
      },
      "outputs": [],
      "source": [
        " # Call the pandas dataframe command to convert the data into a frame which can be used further\n",
        "# Note you are converting data type from Numpy array to Pandas\n",
        "X = pd.DataFrame(X, columns = [\"X1\", \"X2\", \"X3\", \"Credit Score\", \"Gender\",\n",
        "                               \"Age\",\"Tenure\", \"Balance\", \"NumofProducts\",\n",
        "                               \"HasCrCard\", \"IsActive Member\", \"Estimated Salary\"])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rofwOrDg_jtt"
      },
      "outputs": [],
      "source": [
        "X = X.drop(\"X1\", axis = 1)\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LidQ0ItR_nCM"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "# The train_test_split library function is located in sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnTgAi8M_rFh"
      },
      "outputs": [],
      "source": [
        "# Feature Scaling\n",
        "# To standardize the data get the StandardScaler function from sklearn.preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# Pass on the functionality to a new variable called sc\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "# The model is trained to recognize the mean and standard deviation of train data\n",
        "# If it is working properly the test data using the mean and standard deviation of train data should give good reults\n",
        "X_test = sc.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQdntmo9V5o6"
      },
      "outputs": [],
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "# Sequential because the model has all layers in a sequence.\n",
        "from keras.models import Sequential\n",
        "# Dense implies hidden layers which we cannot access from outside\n",
        "# These are built in Keras functions\n",
        "from keras.layers import Dense\n",
        "# Initialising the Deep Learning Model\n",
        "classifier = Sequential()\n",
        "# Adding the input layer\n",
        "# Input_dimensions = 11-\n",
        "# The first hidden layer has 6 units, weights are taken randomly from an uniform distribution and activation is ReLu\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "# Adding the output layer\n",
        "# Here the activtation function is Sigmoid as it is a binary classification problem\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "# Compiling the DNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "# Fitting the DNN to the Training set\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do2aNL1_WB8K"
      },
      "outputs": [],
      "source": [
        "# Computation of Accuracy directly\n",
        "from sklearn import metrics\n",
        "#y_pred = classifier.predict(X_test)\n",
        "i = [0.05, 0.1, 0.15, 0.2,0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "accuracy= []\n",
        "for cutoff in i:\n",
        "  y_pred = (classifier.predict(X_test) > cutoff) # compare each element of the array with the cutoff\n",
        "  accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMQ80eKQWHJK"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "# Predicting the Test set results\n",
        "# Determine if the value is less than or more than the cut-off value\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot = True, fmt='');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jN6jKm2AWR91"
      },
      "outputs": [],
      "source": [
        "# New Customer\n",
        "# Geography: France (0,0)\n",
        "# Credit Score: 600\n",
        "# Gender: Male (1)\n",
        "# Age: 40 years old\n",
        "# Tenure: 3 years\n",
        "# Balance: $60000\n",
        "# Number of Products: 2\n",
        "# Does this customer have a credit card ? Yes (1)\n",
        "# Is this customer an Active Member: Yes (1)\n",
        "# Estimated Salary: $50000\n",
        "# Predict the class of this customer\n",
        "\n",
        "\n",
        "new_customer = classifier.predict(sc.transform(np.array([[0,0,600,1,40,3,60000,2,1,1,50000]])))\n",
        "# You will get a probability value for new_customer\n",
        "# Then you compare with the cut-off\n",
        "print(\"Probability of new customer:\", new_customer)\n",
        "new_prediction = (new_customer>0.5)\n",
        "new_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJl4WI2sWMfH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
